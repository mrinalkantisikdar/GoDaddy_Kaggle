{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Dataset Description\n",
    "Your challenge in this competition is to forecast microbusiness activity across the United States, as measured by the density of microbusinesses in US counties. Microbusinesses are often too small or too new to show up in traditional economic data sources, but microbusiness activity may be correlated with other economic indicators of general interest.\n",
    "\n",
    "As historic economic data are widely available, this is a forecasting competition. The forecasting phase public leaderboard and final private leaderboard will be determined using data gathered after the submission period closes. You will make static forecasts that can only incorporate information available before the end of the submission period. This means that while we will rescore submissions during the forecasting period we will not rerun any notebooks.\n",
    "\n",
    "Files\n",
    "A great deal of data is publicly available about counties and we have not attempted to gather it all here. You are strongly encouraged to use external data sources for features.\n",
    "\n",
    "train.csv\n",
    "\n",
    "row_id - An ID code for the row.\n",
    "cfips - A unique identifier for each county using the Federal Information Processing System. The first two digits correspond to the state FIPS code, while the following 3 represent the county.\n",
    "county_name - The written name of the county.\n",
    "state_name - The name of the state.\n",
    "first_day_of_month - The date of the first day of the month.\n",
    "microbusiness_density - Microbusinesses per 100 people over the age of 18 in the given county. This is the target variable. The population figures used to calculate the density are on a two-year lag due to the pace of update provided by the U.S. Census Bureau, which provides the underlying population data annually. 2021 density figures are calculated using 2019 population figures, etc.\n",
    "active - The raw count of microbusinesses in the county. Not provided for the test set.\n",
    "sample_submission.csv A valid sample submission. This file will remain unchanged throughout the competition.\n",
    "\n",
    "row_id - An ID code for the row.\n",
    "microbusiness_density - The target variable.\n",
    "test.csv Metadata for the submission rows. This file will remain unchanged throughout the competition.\n",
    "\n",
    "row_id - An ID code for the row.\n",
    "cfips - A unique identifier for each county using the Federal Information Processing System. The first two digits correspond to the state FIPS code, while the following 3 represent the county.\n",
    "first_day_of_month - The date of the first day of the month.\n",
    "revealed_test.csv During the submission period, only the most recent month of data will be used for the public leaderboard. Any test set data older than that will be published in revealed_test.csv, closely following the usual data release cycle for the microbusiness report. We expect to publish one copy of revealed_test.csv in mid February. This file's schema will match train.csv.\n",
    "\n",
    "census_starter.csv Examples of useful columns from the Census Bureau's American Community Survey (ACS) at data.census.gov. The percentage fields were derived from the raw counts provided by the ACS. All fields have a two year lag to match what information was avaiable at the time a given microbusiness data update was published.\n",
    "\n",
    "pct_bb_[year] - The percentage of households in the county with access to broadband of any type. Derived from ACS table B28002: PRESENCE AND TYPES OF INTERNET SUBSCRIPTIONS IN HOUSEHOLD.\n",
    "cfips - The CFIPS code.\n",
    "pct_college_[year] - The percent of the population in the county over age 25 with a 4-year college degree. Derived from ACS table S1501: EDUCATIONAL ATTAINMENT.\n",
    "pct_foreign_born_[year] - The percent of the population in the county born outside of the United States. Derived from ACS table DP02: SELECTED SOCIAL CHARACTERISTICS IN THE UNITED STATES.\n",
    "pct_it_workers_[year] - The percent of the workforce in the county employed in information related industries. Derived from ACS table S2405: INDUSTRY BY OCCUPATION FOR THE CIVILIAN EMPLOYED POPULATION 16 YEARS AND OVER.\n",
    "median_hh_inc_[year] - The median household income in the county. Derived from ACS table S1901: INCOME IN THE PAST 12 MONTHS (IN 2021 INFLATION-ADJUSTED DOLLARS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-01-12T11:33:13.662223Z",
     "iopub.status.busy": "2023-01-12T11:33:13.661641Z",
     "iopub.status.idle": "2023-01-12T11:33:15.576617Z",
     "shell.execute_reply": "2023-01-12T11:33:15.575299Z",
     "shell.execute_reply.started": "2023-01-12T11:33:13.662095Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "BASE = r'C:\\Users\\NISER\\Desktop\\GoDaddy_Microbusiness Density Forecasting\\dataset'\n",
    "\n",
    "def smape(y_true, y_pred):\n",
    "    smap = np.zeros(len(y_true))\n",
    "    \n",
    "    num = np.abs(y_true - y_pred)\n",
    "    dem = ((np.abs(y_true) + np.abs(y_pred)) / 2)\n",
    "    \n",
    "    pos_ind = (y_true!=0)|(y_pred!=0)\n",
    "    smap[pos_ind] = num[pos_ind] / dem[pos_ind]\n",
    "    \n",
    "    return 100 * np.mean(smap)\n",
    "\n",
    "def vsmape(y_true, y_pred):\n",
    "    smap = np.zeros(len(y_true))\n",
    "    \n",
    "    num = np.abs(y_true - y_pred)\n",
    "    dem = ((np.abs(y_true) + np.abs(y_pred)) / 2)\n",
    "    \n",
    "    pos_ind = (y_true!=0)|(y_pred!=0)\n",
    "    smap[pos_ind] = num[pos_ind] / dem[pos_ind]\n",
    "    \n",
    "    return 100 * smap\n",
    "\n",
    "\n",
    "#!ls ../input/godaddy-microbusiness-density-forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTION**\n",
    "\n",
    "?? I haven't see anyone use census.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-12T11:33:15.587341Z",
     "iopub.status.busy": "2023-01-12T11:33:15.587003Z",
     "iopub.status.idle": "2023-01-12T11:33:15.674372Z",
     "shell.execute_reply": "2023-01-12T11:33:15.672915Z",
     "shell.execute_reply.started": "2023-01-12T11:33:15.58731Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['pct_bb_2017', 'pct_bb_2018', 'pct_bb_2019', 'pct_bb_2020',\n",
      "       'pct_bb_2021', 'cfips', 'pct_college_2017', 'pct_college_2018',\n",
      "       'pct_college_2019', 'pct_college_2020', 'pct_college_2021',\n",
      "       'pct_foreign_born_2017', 'pct_foreign_born_2018',\n",
      "       'pct_foreign_born_2019', 'pct_foreign_born_2020',\n",
      "       'pct_foreign_born_2021', 'pct_it_workers_2017', 'pct_it_workers_2018',\n",
      "       'pct_it_workers_2019', 'pct_it_workers_2020', 'pct_it_workers_2021',\n",
      "       'median_hh_inc_2017', 'median_hh_inc_2018', 'median_hh_inc_2019',\n",
      "       'median_hh_inc_2020', 'median_hh_inc_2021'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pct_bb_2017</th>\n",
       "      <th>pct_bb_2018</th>\n",
       "      <th>pct_bb_2019</th>\n",
       "      <th>pct_bb_2020</th>\n",
       "      <th>pct_bb_2021</th>\n",
       "      <th>cfips</th>\n",
       "      <th>pct_college_2017</th>\n",
       "      <th>pct_college_2018</th>\n",
       "      <th>pct_college_2019</th>\n",
       "      <th>pct_college_2020</th>\n",
       "      <th>...</th>\n",
       "      <th>pct_it_workers_2017</th>\n",
       "      <th>pct_it_workers_2018</th>\n",
       "      <th>pct_it_workers_2019</th>\n",
       "      <th>pct_it_workers_2020</th>\n",
       "      <th>pct_it_workers_2021</th>\n",
       "      <th>median_hh_inc_2017</th>\n",
       "      <th>median_hh_inc_2018</th>\n",
       "      <th>median_hh_inc_2019</th>\n",
       "      <th>median_hh_inc_2020</th>\n",
       "      <th>median_hh_inc_2021</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76.6</td>\n",
       "      <td>78.9</td>\n",
       "      <td>80.6</td>\n",
       "      <td>82.7</td>\n",
       "      <td>85.5</td>\n",
       "      <td>1001</td>\n",
       "      <td>14.5</td>\n",
       "      <td>15.9</td>\n",
       "      <td>16.1</td>\n",
       "      <td>16.7</td>\n",
       "      <td>...</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.1</td>\n",
       "      <td>55317</td>\n",
       "      <td>58786.0</td>\n",
       "      <td>58731</td>\n",
       "      <td>57982.0</td>\n",
       "      <td>62660.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>74.5</td>\n",
       "      <td>78.1</td>\n",
       "      <td>81.8</td>\n",
       "      <td>85.1</td>\n",
       "      <td>87.9</td>\n",
       "      <td>1003</td>\n",
       "      <td>20.4</td>\n",
       "      <td>20.7</td>\n",
       "      <td>21.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>52562</td>\n",
       "      <td>55962.0</td>\n",
       "      <td>58320</td>\n",
       "      <td>61756.0</td>\n",
       "      <td>64346.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57.2</td>\n",
       "      <td>60.4</td>\n",
       "      <td>60.5</td>\n",
       "      <td>64.6</td>\n",
       "      <td>64.6</td>\n",
       "      <td>1005</td>\n",
       "      <td>7.6</td>\n",
       "      <td>7.8</td>\n",
       "      <td>7.6</td>\n",
       "      <td>7.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>33368</td>\n",
       "      <td>34186.0</td>\n",
       "      <td>32525</td>\n",
       "      <td>34990.0</td>\n",
       "      <td>36422.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62.0</td>\n",
       "      <td>66.1</td>\n",
       "      <td>69.2</td>\n",
       "      <td>76.1</td>\n",
       "      <td>74.6</td>\n",
       "      <td>1007</td>\n",
       "      <td>8.1</td>\n",
       "      <td>7.6</td>\n",
       "      <td>6.5</td>\n",
       "      <td>7.4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2.1</td>\n",
       "      <td>43404</td>\n",
       "      <td>45340.0</td>\n",
       "      <td>47542</td>\n",
       "      <td>51721.0</td>\n",
       "      <td>54277.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65.8</td>\n",
       "      <td>68.5</td>\n",
       "      <td>73.0</td>\n",
       "      <td>79.6</td>\n",
       "      <td>81.0</td>\n",
       "      <td>1009</td>\n",
       "      <td>8.7</td>\n",
       "      <td>8.1</td>\n",
       "      <td>8.6</td>\n",
       "      <td>8.9</td>\n",
       "      <td>...</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>47412</td>\n",
       "      <td>48695.0</td>\n",
       "      <td>49358</td>\n",
       "      <td>48922.0</td>\n",
       "      <td>52830.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pct_bb_2017  pct_bb_2018  pct_bb_2019  pct_bb_2020  pct_bb_2021  cfips  \\\n",
       "0         76.6         78.9         80.6         82.7         85.5   1001   \n",
       "1         74.5         78.1         81.8         85.1         87.9   1003   \n",
       "2         57.2         60.4         60.5         64.6         64.6   1005   \n",
       "3         62.0         66.1         69.2         76.1         74.6   1007   \n",
       "4         65.8         68.5         73.0         79.6         81.0   1009   \n",
       "\n",
       "   pct_college_2017  pct_college_2018  pct_college_2019  pct_college_2020  \\\n",
       "0              14.5              15.9              16.1              16.7   \n",
       "1              20.4              20.7              21.0              20.2   \n",
       "2               7.6               7.8               7.6               7.3   \n",
       "3               8.1               7.6               6.5               7.4   \n",
       "4               8.7               8.1               8.6               8.9   \n",
       "\n",
       "   ...  pct_it_workers_2017  pct_it_workers_2018  pct_it_workers_2019  \\\n",
       "0  ...                  1.3                  1.1                  0.7   \n",
       "1  ...                  1.4                  1.3                  1.4   \n",
       "2  ...                  0.5                  0.3                  0.8   \n",
       "3  ...                  1.2                  1.4                  1.6   \n",
       "4  ...                  1.3                  1.4                  0.9   \n",
       "\n",
       "   pct_it_workers_2020  pct_it_workers_2021  median_hh_inc_2017  \\\n",
       "0                  0.6                  1.1               55317   \n",
       "1                  1.0                  1.3               52562   \n",
       "2                  1.1                  0.8               33368   \n",
       "3                  1.7                  2.1               43404   \n",
       "4                  1.1                  0.9               47412   \n",
       "\n",
       "   median_hh_inc_2018  median_hh_inc_2019  median_hh_inc_2020  \\\n",
       "0             58786.0               58731             57982.0   \n",
       "1             55962.0               58320             61756.0   \n",
       "2             34186.0               32525             34990.0   \n",
       "3             45340.0               47542             51721.0   \n",
       "4             48695.0               49358             48922.0   \n",
       "\n",
       "   median_hh_inc_2021  \n",
       "0             62660.0  \n",
       "1             64346.0  \n",
       "2             36422.0  \n",
       "3             54277.0  \n",
       "4             52830.0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "census = pd.read_csv(os.path.join(BASE,'census_starter.csv'))\n",
    "print(census.columns)\n",
    "census.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Basic processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-12T11:33:15.677117Z",
     "iopub.status.busy": "2023-01-12T11:33:15.676697Z",
     "iopub.status.idle": "2023-01-12T11:33:16.553261Z",
     "shell.execute_reply": "2023-01-12T11:33:16.551961Z",
     "shell.execute_reply.started": "2023-01-12T11:33:15.677079Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(BASE + 'train.csv')\n",
    "test = pd.read_csv(BASE + 'test.csv')\n",
    "sub = pd.read_csv(BASE + 'sample_submission.csv')\n",
    "print(train.shape, test.shape, sub.shape)  # (122265, 7) (25080, 3) (25080, 2)\n",
    "\n",
    "# 1. concatenate train and test\n",
    "train['istest'] = 0\n",
    "test['istest'] = 1\n",
    "raw = pd.concat((train, test)).sort_values(['cfips','row_id']).reset_index(drop=True)\n",
    "# concat train and test data, and sort by cfips first, and then sort by row_id for each cfips\n",
    "# since row_id has a format 'cfips-first day of month', basically we sort by time\n",
    "# because we have both train and test, the index is confounded. so we drop the index first and then give the joined table a new index from 0\n",
    "\n",
    "# 2. change the type of the column 'first_day_of_month' to 'to_datetime'\n",
    "raw['first_day_of_month'] = pd.to_datetime(raw[\"first_day_of_month\"])\n",
    "\n",
    "# 3. for each cfips, fill the 'county' and 'state' for the test part by forward fill\n",
    "# - ffill: propagate last valid observation forward to next valid backfill\n",
    "# - bfill: use next valid observation to fill gap.\n",
    "raw['county'] = raw.groupby('cfips')['county'].ffill()\n",
    "raw['state'] = raw.groupby('cfips')['state'].ffill()\n",
    "# now, test data also have the 'county' and 'state' column value\n",
    "\n",
    "# 4. - NEW COLUMNS: two year and month columns for both train and test\n",
    "raw[\"year\"] = raw[\"first_day_of_month\"].dt.year\n",
    "raw[\"month\"] = raw[\"first_day_of_month\"].dt.month\n",
    "\n",
    "# 5. - NEW COLUMNS: for each cfips, give each month a unique index from 0 to length of that group - 1.\n",
    "#                   dcount become the unique index for each month for a cfips.\n",
    "#                   dcount is the 0-started index for each cfips\n",
    "raw[\"dcount\"] = raw.groupby(['cfips'])['row_id'].cumcount()\n",
    "\n",
    "# 6. - NEW COLUMNS: encode 'county + state' as unique codes; encode 'state' as unique codes\n",
    "raw['county_i'] = (raw['county'] + raw['state']).factorize()[0]\n",
    "raw['state_i'] = raw['state'].factorize()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Anomaly Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-12T11:33:16.580776Z",
     "iopub.status.busy": "2023-01-12T11:33:16.580375Z",
     "iopub.status.idle": "2023-01-12T11:33:16.611528Z",
     "shell.execute_reply": "2023-01-12T11:33:16.610547Z",
     "shell.execute_reply.started": "2023-01-12T11:33:16.580743Z"
    }
   },
   "outputs": [],
   "source": [
    "lag = 1\n",
    "\n",
    "# .shift(lag): for each cfips, shift its density column by lag=1, so the density in each first row will be NAN. -> you get a column with the length = len('density')\n",
    "# .bfill(): fill NaN with the next valid density, so the density in each cfips' first row will be the original value, but note that\n",
    "#           1001's density from 2022-12-01 to 2023-06-01 will be back filled by the first density of 1003 (the next cfips), in this new column 'mbd_lag_1'.\n",
    "#           but, it turns out that doesn't really matter\n",
    "# NOTE THAT, in the engineering, 'mbd_lag_1' is overwrite by new feature\n",
    "raw[f'mbd_lag_{lag}'] = raw.groupby('cfips')['microbusiness_density'].shift(lag).bfill()\n",
    "\n",
    "# basically, 'dif' means the 'percentage increment' of the density from the previous month to this month\n",
    "raw['dif'] = (raw['microbusiness_density'] / raw[f'mbd_lag_{lag}']).fillna(1).clip(0, None) - 1\n",
    "\n",
    "# if there are zeros in density, then we need to deal with special cases:\n",
    "#    density  mbd_lag_1  div  fillna  clip  diff\n",
    "#       1         1       1                 -> 0   \n",
    "#       2         1       2                 -> 1\n",
    "#       0         2       0                 -> -1\n",
    "#       0         0      inf                -> inf     special cases\n",
    "#       4         0      inf                -> inf     special cases\n",
    "#      Nan        4      Nan    -> 1        -> 0\n",
    "#      Nan        Nan    Nan    -> 1        -> 0\n",
    "#      Nan        Nan    Nan    -> 1        -> 0\n",
    "\n",
    "# --------------------------------------------\n",
    "raw.loc[(raw[f'mbd_lag_{lag}']==0), 'dif'] = 0\n",
    "#    density  mbd_lag_1  div  fillna   diff\n",
    "#       1         1       1          -> 0   \n",
    "#       2         1       2          -> 1\n",
    "#       0         2       0          -> -1\n",
    "#       0         0      inf         -> inf     special cases -> 0\n",
    "#       4         0      inf         -> inf     special cases -> 0\n",
    "#      Nan        4      Nan    -> 1 -> 0\n",
    "#      Nan        Nan    Nan    -> 1 -> 0\n",
    "#      Nan        Nan    Nan    -> 1 -> 0\n",
    "\n",
    "\n",
    "raw.loc[(raw[f'microbusiness_density']>0) & (raw[f'mbd_lag_{lag}']==0), 'dif'] = 1  \n",
    "#    density  mbd_lag_1  div  fillna   diff\n",
    "#       1         1       1          -> 0   \n",
    "#       2         1       2          -> 1\n",
    "#       0         2       0          -> -1\n",
    "#       0         0      inf         -> inf     special cases -> 0\n",
    "#       4         0      inf         -> inf     special cases -> 0 -> 1   # is 1 a reasonable number?\n",
    "#      Nan        4      Nan    -> 1 -> 0\n",
    "#      Nan        Nan    Nan    -> 1 -> 0\n",
    "#      Nan        Nan    Nan    -> 1 -> 0\n",
    "\n",
    "# -------------------------\n",
    "\n",
    "raw['dif'] = raw['dif'].abs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's see which dcount (time point) has a SIGNIFINCANT increase than the previous month!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-12T11:33:17.255307Z",
     "iopub.status.busy": "2023-01-12T11:33:17.254698Z",
     "iopub.status.idle": "2023-01-12T11:33:17.512505Z",
     "shell.execute_reply": "2023-01-12T11:33:17.511077Z",
     "shell.execute_reply.started": "2023-01-12T11:33:17.255274Z"
    }
   },
   "outputs": [],
   "source": [
    "raw.groupby('dcount')['dif'].sum().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smoothing & Outlier correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-12T11:33:17.969403Z",
     "iopub.status.busy": "2023-01-12T11:33:17.969011Z",
     "iopub.status.idle": "2023-01-12T11:33:24.825324Z",
     "shell.execute_reply": "2023-01-12T11:33:24.824199Z",
     "shell.execute_reply.started": "2023-01-12T11:33:17.969371Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outliers = []   # record which cfips has outliners\n",
    "cnt = 0         # the tot num of outliners\n",
    "\n",
    "for o in tqdm(raw.cfips.unique()):     # each cfips\n",
    "    \n",
    "    indices = (raw['cfips']==o)        # get all the idx for that cfips\n",
    "    tmp = raw.loc[indices].copy().reset_index(drop=True)   # get all the rows for the cfips, reset_index make each tmp index from zero\n",
    "    var = tmp.microbusiness_density.values.copy()          # copy density data for the current cfips\n",
    "    #vmax = np.max(var[:38]) - np.min(var[:38])\n",
    "    \n",
    "    for i in range(37, 2, -1):         # idx 37 ~ 3. Note: 0 ~ 38 is training data\n",
    "                                       # why not consider 38? 2?  # i think you can even set it to 0\n",
    "        thr = 0.20*np.mean(var[:i])    # use 20% average of the points before current point i as the anomaly value TH\n",
    "        difa = abs(var[i]-var[i-1])    # if the current point i's increase is bigger than thr, we consider it as a anomaly change, not natural trend\n",
    "        if (difa>=thr):                # so we 'lift' all the previous values to the same 'stage' of the current point\n",
    "            var[:i] *= (var[i]/var[i-1])\n",
    "            \n",
    "            outliers.append(o)         # save which cfips has outliers\n",
    "            cnt+=1                     # total count\n",
    "    \n",
    "    # why not set the above for loop as range(37,0,-1)? so we don't need the line below\n",
    "    var[0] = var[1]*0.99               # why do this hard code 0.99? make the first -> second unchanged almost? \n",
    "    \n",
    "    raw.loc[indices, 'microbusiness_density'] = var  # the smoothed density\n",
    "    \n",
    "outliers = np.unique(outliers)\n",
    "len(outliers), cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-12T11:33:24.827355Z",
     "iopub.status.busy": "2023-01-12T11:33:24.826985Z",
     "iopub.status.idle": "2023-01-12T11:33:25.067666Z",
     "shell.execute_reply": "2023-01-12T11:33:25.066346Z",
     "shell.execute_reply.started": "2023-01-12T11:33:24.827324Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot again\n",
    "lag = 1\n",
    "raw[f'mbd_lag_{lag}'] = raw.groupby('cfips')['microbusiness_density'].shift(lag).bfill()\n",
    "raw['dif'] = (raw['microbusiness_density'] / raw[f'mbd_lag_{lag}']).fillna(1).clip(0, None) - 1\n",
    "raw.loc[(raw[f'mbd_lag_{lag}']==0), 'dif'] = 0\n",
    "raw.loc[(raw[f'microbusiness_density']>0) & (raw[f'mbd_lag_{lag}']==0), 'dif'] = 1\n",
    "raw['dif'] = raw['dif'].abs()\n",
    "raw.groupby('dcount')['dif'].sum().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-12T11:33:25.069311Z",
     "iopub.status.busy": "2023-01-12T11:33:25.06895Z",
     "iopub.status.idle": "2023-01-12T11:33:25.520534Z",
     "shell.execute_reply": "2023-01-12T11:33:25.519476Z",
     "shell.execute_reply.started": "2023-01-12T11:33:25.06928Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot two cfips density change over time\n",
    "raw.loc[raw.cfips == 1013].plot(x='dcount', y='microbusiness_density')\n",
    "raw.loc[raw.cfips == 21215].plot(x='dcount', y='microbusiness_density')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. SMAPE is a relative metric so target must be converted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**COLUMN 'target' is the next month increment compare to this month (in %)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-12T11:33:25.523497Z",
     "iopub.status.busy": "2023-01-12T11:33:25.523132Z",
     "iopub.status.idle": "2023-01-12T11:33:25.543068Z",
     "shell.execute_reply": "2023-01-12T11:33:25.541845Z",
     "shell.execute_reply.started": "2023-01-12T11:33:25.523466Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raw['target'] = raw.groupby('cfips')['microbusiness_density'].shift(-1)  # shift UP\n",
    "raw['target'] = raw['target']/raw['microbusiness_density'] - 1   # next / this month - 1 = the next month increment\n",
    "                                                                 # NOTE: dcount = 38 doesn't have target value - not next month to compare   \n",
    "# two special cases, hard code to 0.0\n",
    "raw.loc[raw['cfips']==28055, 'target'] = 0.0\n",
    "raw.loc[raw['cfips']==48269, 'target'] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-12T11:33:25.544657Z",
     "iopub.status.busy": "2023-01-12T11:33:25.544323Z",
     "iopub.status.idle": "2023-01-12T11:33:25.951836Z",
     "shell.execute_reply": "2023-01-12T11:33:25.950717Z",
     "shell.execute_reply.started": "2023-01-12T11:33:25.544628Z"
    }
   },
   "outputs": [],
   "source": [
    "raw['target'].clip(-0.05, 0.05).hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-12T11:33:25.953495Z",
     "iopub.status.busy": "2023-01-12T11:33:25.953147Z",
     "iopub.status.idle": "2023-01-12T11:33:26.364949Z",
     "shell.execute_reply": "2023-01-12T11:33:26.363692Z",
     "shell.execute_reply.started": "2023-01-12T11:33:25.953464Z"
    }
   },
   "outputs": [],
   "source": [
    "raw['target'].clip(-0.2, 0.2).hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can see that the increase to the next month usually exceed 20% of the current month."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**COLUMN 'lastactive'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-12T11:33:26.367137Z",
     "iopub.status.busy": "2023-01-12T11:33:26.366583Z",
     "iopub.status.idle": "2023-01-12T11:33:26.378971Z",
     "shell.execute_reply": "2023-01-12T11:33:26.377991Z",
     "shell.execute_reply.started": "2023-01-12T11:33:26.36709Z"
    }
   },
   "outputs": [],
   "source": [
    "# for each cfips, get the last active value and assign it to the NEW column 'lastactive'\n",
    "raw['lastactive'] = raw.groupby('cfips')['active'].transform('last')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-12T11:33:26.380912Z",
     "iopub.status.busy": "2023-01-12T11:33:26.38047Z",
     "iopub.status.idle": "2023-01-12T11:33:26.653018Z",
     "shell.execute_reply": "2023-01-12T11:33:26.652023Z",
     "shell.execute_reply.started": "2023-01-12T11:33:26.380849Z"
    }
   },
   "outputs": [],
   "source": [
    "raw['lastactive'].clip(0, 100000).hist(bins=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**COLUMN 'lasttarget'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-12T11:33:26.655074Z",
     "iopub.status.busy": "2023-01-12T11:33:26.654559Z",
     "iopub.status.idle": "2023-01-12T11:33:26.678334Z",
     "shell.execute_reply": "2023-01-12T11:33:26.677158Z",
     "shell.execute_reply.started": "2023-01-12T11:33:26.655024Z"
    }
   },
   "outputs": [],
   "source": [
    "# for each cfips, get dcount=28 (2021-12-01)'s density, so we get\n",
    "#   cfips    2021-12-01's density\n",
    "#   1001      3.286307\n",
    "#   1003      7.930010\n",
    "#         ...\n",
    "# dt is a mapping table for the next step\n",
    "dt = raw.loc[raw.dcount==28].groupby('cfips')['microbusiness_density'].agg('last')\n",
    "\n",
    "# basically, use each cfips' 2021-12-01 density as the value for 'lasttarget' column \n",
    "# NOTE: this is the actual density value! not the target value. why 28?\n",
    "raw['lasttarget'] = raw['cfips'].map(dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-12T11:33:26.682116Z",
     "iopub.status.busy": "2023-01-12T11:33:26.681764Z",
     "iopub.status.idle": "2023-01-12T11:33:26.692632Z",
     "shell.execute_reply": "2023-01-12T11:33:26.691276Z",
     "shell.execute_reply.started": "2023-01-12T11:33:26.682086Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_features(raw, target='microbusiness_density', target_act='active_tmp', lags = 6):\n",
    "    '''\n",
    "    e.g.,\n",
    "    target = 'target'\n",
    "    target_act = 'active'\n",
    "    lags = 4\n",
    "    '''\n",
    "    \n",
    "    feats = []\n",
    "    for lag in range(1, lags):  # 1 ~ 3\n",
    "        \n",
    "        # for each cfips, shift the 'target' column by 1,2 and 3\n",
    "        # the original 'target' column has values from 0 to 37, note that dcount = 38 (2022-10-01) doesn't have a target value \n",
    "        raw[f'mbd_lag_{lag}'] = raw.groupby('cfips')[target].shift(lag)\n",
    "        \n",
    "        # for each cfips, the diff between the current avtive value and the previous 1,2,and 3 months' active values\n",
    "        # the original 'active' column has values from 0 to 38\n",
    "        raw[f'act_lag_{lag}'] = raw.groupby('cfips')[target_act].diff(lag)\n",
    "        \n",
    "        # the shifted 'target' and 'active' are taken as features\n",
    "        # basically, for each month, the previous 1,2,3 months' target and active are taken into consideration\n",
    "        feats.append(f'mbd_lag_{lag}')\n",
    "        feats.append(f'act_lag_{lag}')\n",
    "    \n",
    "    # the sum of the previous 2,4,6 months 'target' value\n",
    "    lag = 1\n",
    "    for window in [2, 4, 6]:\n",
    "        raw[f'mbd_rollmea{window}_{lag}'] = raw.groupby('cfips')[f'mbd_lag_{lag}'].transform(lambda s: s.rolling(window, min_periods=1).sum())   \n",
    "        \n",
    "        ## the diff between the previous month and the sum of previous 6 months. the original notebook doesn't use it\n",
    "        ##raw[f'mbd_rollmea{window}_{lag}'] = raw[f'mbd_lag_{lag}'] - raw[f'mbd_rollmea{window}_{lag}']\n",
    "        \n",
    "        feats.append(f'mbd_rollmea{window}_{lag}')\n",
    "        \n",
    "    return raw, feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-12T11:33:26.695587Z",
     "iopub.status.busy": "2023-01-12T11:33:26.69435Z",
     "iopub.status.idle": "2023-01-12T11:33:31.240542Z",
     "shell.execute_reply": "2023-01-12T11:33:31.239412Z",
     "shell.execute_reply.started": "2023-01-12T11:33:26.695543Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Build Features based in lag of target\n",
    "raw, feats = build_features(raw, 'target', 'active', lags = 4)\n",
    "\n",
    "# the state code is a feature\n",
    "features = ['state_i']\n",
    "features += feats\n",
    "print(features)\n",
    "\n",
    "raw.loc[raw.dcount==38, features].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-12T11:33:31.242511Z",
     "iopub.status.busy": "2023-01-12T11:33:31.242113Z",
     "iopub.status.idle": "2023-01-12T11:33:31.776575Z",
     "shell.execute_reply": "2023-01-12T11:33:31.775566Z",
     "shell.execute_reply.started": "2023-01-12T11:33:31.242479Z"
    }
   },
   "outputs": [],
   "source": [
    "# why do we have to care about 'lasttarget'?\n",
    "# ' basically, use each cfips' 2021-12-01 density as the value for 'lasttarget' column \n",
    "#   NOTE: this is the actual density value! not the target value. why 28?'\n",
    "raw['lasttarget'].clip(0,10).hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the meaning of the blacklist? how to get it? see section 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-12T11:33:31.779132Z",
     "iopub.status.busy": "2023-01-12T11:33:31.77817Z",
     "iopub.status.idle": "2023-01-12T11:33:31.823213Z",
     "shell.execute_reply": "2023-01-12T11:33:31.821686Z",
     "shell.execute_reply.started": "2023-01-12T11:33:31.779085Z"
    }
   },
   "outputs": [],
   "source": [
    "blacklist = [\n",
    "    'North Dakota', 'Iowa', 'Kansas', 'Nebraska', 'South Dakota','New Mexico', 'Alaska', 'Vermont'\n",
    "]\n",
    "blacklistcfips = [\n",
    "1019,1027,1029,1035,1039,1045,1049,1057,1067,1071,1077,1085,1091,1099,1101,1123,1131,1133,4001,4012,4013,4021,4023,5001,5003,5005,5017,5019,5027,5031,5035,5047,5063,5065,5071,5081,5083,5087,5091,5093,5107,5109,5115,5121,5137,5139,5141,5147,6003,6015,6027,6033,6053,6055,6057,6071,6093,6097,6103,6105,6115,8003,8007,8009,8019,8021,8023,8047,8051,8053,8055,8057,8059,8061,8065,8067,8069,8071,8073,8075,8085,8091,8093,8097,8099,8103,8105,8107,8109,8111,8115,8117,8121,9007,9009,9015,12009,12017,12019,12029,12047,12055,12065,12075,12093,12107,12127,13005,13007,13015,13017,13019,13027,13035,13047,13065,13081,13083,13099,13107,13109,13117,13119,13121,13123,13125,13127,13135,13143,13147,13161,13165,13171,13175,13181,13193,13201,13221,13225,13229,13231,13233,13245,13247,13249,13257,13279,13281,13287,13289,13293,13301,13319,15001,15005,15007,16001,16003,16005,16007,16013,16015,16017,16023,16025,16029,16031,16033,16035,16037,16043,16045,16049,16061,16063,16067,17001,17003,17007,17009,17013,17015,17023,17025,17031,17035,17045,17051,17059,17061,17063,17065,17067,17069,17075,17077,17081,17085,17087,17103,17105,17107,17109,17115,17117,17123,17127,17133,17137,17141,17143,17147,17153,17167,17169,17171,17177,17179,17181,17185,17187,17193,18001,18007,18009,18013,18015,18019,18021,18025,18035,18037,18039,18041,18053,18061,18075,18079,18083,18087,18099,18103,18111,18113,18115,18137,18139,18145,18153,18171,18179,21001,21003,21013,21017,21023,21029,21035,21037,21039,21045,21047,21055,21059,21065,21075,21077,21085,21091,21093,21097,21099,21101,21103,21115,21125,21137,21139,21141,21149,21155,21157,21161,21165,21179,21183,21191,21197,21199,21215,21217,21223,21227,21237,21239,22019,22021,22031,22039,22041,22047,22069,22085,22089,22101,22103,22109,22111,22115,22119,22121,23003,23009,23021,23027,23029,24011,24027,24029,24031,24035,24037,24039,24041,25011,25015,26003,26007,26011,26019,26021,26025,26027,26033,26037,26041,26043,26051,26053,26057,26059,26061,26065,26071,26077,26079,26083,26089,26097,26101,26103,26109,26111,26115,26117,26119,26127,26129,26131,26135,26141,26143,26155,26161,26165,27005,27011,27013,27015,27017,27021,27023,27025,27029,27047,27051,27055,27057,27065,27069,27073,27075,27077,27079,27087,27091,27095,27101,27103,27105,27107,27109,27113,27117,27119,27123,27125,27129,27131,27133,27135,27141,27147,27149,27155,27159,27167,27169,28017,28019,28023,28025,28035,28045,28049,28061,28063,28093,28097,28099,28125,28137,28139,28147,28159,29001,29015,29019,29031,29033,29041,29049,29051,29055,29057,29063,29065,29069,29075,29085,29089,29101,29103,29111,29121,29123,29125,29135,29137,29139,29143,29157,29159,29161,29167,29171,29173,29175,29177,29183,29195,29197,29199,29203,29205,29207,29209,29213,29215,29217,29223,29227,29229,30005,30009,30025,30027,30033,30035,30037,30039,30045,30049,30051,30053,30055,30057,30059,30069,30071,30073,30077,30079,30083,30085,30089,30091,30093,30101,30103,30105,30107,30109,32005,32009,32017,32023,32027,32029,32510,33005,33007,34021,34027,34033,34035,36011,36017,36023,36033,36043,36047,36049,36051,36057,36061,36067,36083,36091,36097,36103,36107,36113,36115,36121,36123,37005,37009,37011,37017,37023,37029,37031,37049,37061,37075,37095,37117,37123,37131,37137,37151,37187,37189,37197,39005,39009,39015,39017,39019,39023,39037,39039,39043,39049,39053,39057,39063,39067,39071,39077,39085,39087,39091,39097,39105,39107,39113,39117,39119,39125,39127,39129,39135,39137,39151,39153,39157,40003,40013,40015,40023,40025,40027,40035,40039,40043,40045,40053,40055,40057,40059,40065,40067,40073,40077,40079,40099,40105,40107,40111,40115,40123,40127,40129,40133,40141,40147,40151,40153,41001,41007,41013,41015,41017,41021,41025,41031,41033,41037,41051,41055,41063,41067,41069,42005,42007,42011,42013,42015,42019,42027,42029,42031,42035,42053,42057,42067,42071,42083,42085,42093,42097,42105,42111,42113,42115,42123,42125,42127,42129,44005,44007,44009,45001,45009,45021,45025,45031,45059,45067,45071,45073,45089,47001,47005,47013,47015,47019,47021,47023,47027,47035,47039,47041,47047,47055,47057,47059,47061,47069,47073,47075,47077,47083,47087,47099,47105,47121,47127,47131,47133,47135,47137,47147,47151,47153,47159,47161,47163,47169,47177,47183,47185,48001,48011,48017,48019,48045,48057,48059,48063,48065,48073,48077,48079,48081,48083,48087,48095,48101,48103,48107,48109,48115,48117,48119,48123,48125,48129,48149,48151,48153,48155,48159,48161,48165,48175,48189,48191,48195,48197,48211,48221,48229,48233,48235,48237,48239,48241,48243,48245,48255,48261,48263,48265,48267,48269,48275,48277,48283,48293,48299,48305,48311,48313,48319,48321,48323,48327,48333,48345,48347,48355,48369,48377,48379,48383,48387,48389,48401,48403,48413,48417,48431,48433,48437,48443,48447,48453,48455,48457,48461,48463,48465,48469,48471,48481,48483,48485,48487,48495,48499,49001,49009,49013,49019,49027,49031,49045,51005,51017,51025,51029,51031,51036,51037,51043,51057,51059,51065,51071,51073,51077,51079,51083,51091,51095,51097,51101,51111,51115,51119,51121,51127,51135,51147,51155,51159,51165,51167,51171,51173,51181,51183,51191,51197,51530,51590,51610,51620,51670,51678,51720,51735,51750,51770,51810,51820,53013,53019,53023,53031,53033,53037,53039,53041,53047,53065,53069,53071,53075,54013,54019,54025,54031,54033,54041,54049,54055,54057,54063,54067,54071,54077,54079,54085,54089,54103,55001,55003,55005,55007,55011,55017,55021,55025,55029,55037,55043,55047,55049,55051,55061,55065,55067,55075,55077,55091,55097,55101,55103,55109,55117,55123,55125,55127,56007,56009,56011,56015,56017,56019,56021,56027,56031,56037,56043,56045,\n",
    "12061,  6095, 49025, 18073, 29029, 29097, 48419, 51830, 30067, 26095, 18159, 32001, 54065, 54027, 13043, 48177, 55069, 48137, 30087, 29007, 13055, 48295, 28157, 29037, 45061, 22053, 13199, 47171, 53001, 55041, 51195, 18127, 29151, 48307, 51009, 16047, 29133,  5145, 17175, 21027, 48357, 29179, 13023, 16077, 48371, 21057, 16039, 21143, 48435, 48317, 48475,  5129, 36041, 48075, 29017, 47175, 39167, 47109, 17189, 17173, 28009, 39027, 48133, 18129, 48217, 40081, 36021,  6005, 42099, 18051, 36055, 53051, 6109, 21073, 27019,  6051, 48055,  8083, 48503, 17021, 10003, 41061, 22001, 22011, 21205, 48223, 51103, 51047, 16069, 17033, 41011,  6035, 47145, 27083, 18165, 36055, 12001, 26159,  8125, 34017,\n",
    "28141, 55119, 48405, 40029, 18125, 21135, 29073, 55115, 37149,55039, 26029, 12099, 13251, 48421, 39007, 41043, 22015, 37115,54099, 51137, 22049, 55131, 17159, 56001, 40005, 18017, 28091,47101, 27037, 29005, 13239, 21019, 55085, 48253, 51139, 40101,13283, 18049, 39163, 45049, 51113,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-12T11:33:33.912691Z",
     "iopub.status.busy": "2023-01-12T11:33:33.911448Z",
     "iopub.status.idle": "2023-01-12T11:33:33.921706Z",
     "shell.execute_reply": "2023-01-12T11:33:33.920373Z",
     "shell.execute_reply.started": "2023-01-12T11:33:33.912641Z"
    }
   },
   "outputs": [],
   "source": [
    "# threshold\n",
    "ACT_THR = 1.8\n",
    "ABS_THR = 1.0\n",
    "\n",
    "# define 3 new columns for use\n",
    "raw['ypred_last'] = np.nan\n",
    "raw['ypred'] = np.nan\n",
    "raw['k'] = 1.\n",
    "\n",
    "VAL = []\n",
    "BEST_ROUNDS = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-12T11:33:35.004944Z",
     "iopub.status.busy": "2023-01-12T11:33:35.004335Z",
     "iopub.status.idle": "2023-01-12T11:35:50.311762Z",
     "shell.execute_reply": "2023-01-12T11:35:50.310522Z",
     "shell.execute_reply.started": "2023-01-12T11:33:35.00491Z"
    }
   },
   "outputs": [],
   "source": [
    "for TS in range(29, 38):  # from 29 to 37.  1) is it the reason why 'lasttarget' use 'dcount=28'?  \n",
    "                          # the actual density pred you give is 30 to 38  \n",
    "    print(TS)\n",
    "    \n",
    "    # --- define the model\n",
    "    model = xgb.XGBRegressor(\n",
    "        objective='reg:pseudohubererror',   # why this objective?\n",
    "        #objective='reg:squarederror',\n",
    "        tree_method=\"hist\",                 # \n",
    "        n_estimators=4999,                  # iterations\n",
    "        learning_rate=0.0075,\n",
    "        max_leaves = 17,    \n",
    "        subsample=0.50,                     # sample used for each iteration\n",
    "        colsample_bytree=0.50,              # features used for each iteration\n",
    "        max_bin=4096,                       # \n",
    "        n_jobs=2,\n",
    "        eval_metric='mae',                  # \n",
    "        early_stopping_rounds=70,\n",
    "    )\n",
    "    \n",
    "    # --- get training data\n",
    "    train_indices = (raw.istest==0) & (raw.dcount  < TS) & (raw.dcount >= 1) & (raw.lastactive>ACT_THR) & (raw.lasttarget>ABS_THR) \n",
    "    #                no test data   |    training month = [1,TS)             |                   1.8     |                    1\n",
    "    #                                    why not use 0?                                                              \n",
    "    #                                    because has undefined features, but does 1 has all the features?\n",
    "    # \n",
    "    # note that for each cfips, the 'lastactive' across months are the same, so does the 'lasttarget' column\n",
    "    # so, you either select all the rows or drop all the row for a cfips\n",
    "    #\n",
    "    # ‘lasttarget’: for each cfips, the density in dcount = 28 '2021-12-01'\n",
    "    # 'lastactive': for each cfips, the last active value (in dcount = 38)  '2022-10-01'\n",
    "    \n",
    "    # --- get testing data\n",
    "    valid_indices = (raw.istest==0) & (raw.dcount == TS)  # note: more cfips than training data, but we exclude some of them later\n",
    "    \n",
    "    # --- model fit\n",
    "    model.fit(\n",
    "        raw.loc[train_indices, features],\n",
    "        raw.loc[train_indices, 'target'].clip(-0.0043, 0.0045),    # why clip ? the increase or decrease is confined in the range (-0.0043, 0.0045). reasonable?\n",
    "        eval_set=[(raw.loc[valid_indices, features], raw.loc[valid_indices, 'target'])],\n",
    "        verbose=500,\n",
    "    )\n",
    "    \n",
    "    # --- save best iteration\n",
    "    best_rounds = model.best_iteration\n",
    "    BEST_ROUNDS.append(model.best_iteration)\n",
    "    \n",
    "    # --- pred the current validation set, note the pred is the increment comparing to TS+1\n",
    "    ypred = model.predict(raw.loc[valid_indices, features])\n",
    "    \n",
    "    # becasue we pred the increment for the next month, so we need to add 1\n",
    "    raw.loc[valid_indices, 'k'] = ypred + 1\n",
    "    # if you multiple it with 'density' in TS, you get next month TS+1 density prediction\n",
    "    raw.loc[valid_indices, 'k'] = raw.loc[valid_indices,'k'] * raw.loc[valid_indices,'microbusiness_density']\n",
    "\n",
    "    # --- ACTUALLY, WE ARE PREDICTING **TS+1** ---\n",
    "    # 1. define two mappings, lastval and dt\n",
    "    lastval = raw.loc[raw.dcount==TS, ['cfips', 'microbusiness_density']].set_index('cfips').to_dict()['microbusiness_density']\n",
    "    # for all the current validation TS, get cfips and density\n",
    "    # then, set cfips to index, so we make a dict -> cfips: the density for TS\n",
    "    # e.g., { 'microbusiness_density':{1001: 3.2967808, 1003: 7.733397, 1005: 1.1866289, ...} }\n",
    "    # this is a map for later use\n",
    "    \n",
    "    dt = raw.loc[raw.dcount==TS, ['cfips', 'k']].set_index('cfips').to_dict()['k']\n",
    "    # e.g., { 'k':{1001: pred for TS+1 month ACTUAL density, 1003: , 1005: , ...} }\n",
    "    # this is a map for later use\n",
    "    \n",
    "    # 2. define a tmp dataframe for the preds of TS+1\n",
    "    df = raw.loc[raw.dcount==(TS+1), ['cfips', 'microbusiness_density', 'state', 'lastactive', 'mbd_lag_1']].reset_index(drop=True)\n",
    "    # get all the cfips's TS+1                                         the 2022-10-01 active |  'target' value in TS\n",
    "    \n",
    "    # ATTACH the mappings to df columns\n",
    "    df['pred'] = df['cfips'].map(dt)         # put TS+1 density pred to 'pred' column of the TS+1 specific df\n",
    "    df['lastval'] = df['cfips'].map(lastval) # put the TS density to 'lastval' column of df\n",
    "    \n",
    "    # FOR SOME CASES, WE DON'T WANT TO USE THE PREDICTIONS BY THE MODEL, INSTEAD, WE WANT TO USE THE TS DENSITY.\n",
    "    # case1. for each cfips, if the last active in dcount=38 is smaller than ACT_THR, (which means the business scale is considered as small)\n",
    "    #    then, we don't use the pred above, instead, use the TS density\n",
    "    df.loc[df['lastactive']<=ACT_THR, 'pred'] = df.loc[df['lastactive']<=ACT_THR, 'lastval']\n",
    "    \n",
    "    # case2. for each cfips, if the TS actual density is smaller than ABS_THR, (which means the recent trend is small?)\n",
    "    #    then, we don't use the pred above, instead, use the TS density\n",
    "    df.loc[df['lastval']<=ABS_THR, 'pred'] = df.loc[df['lastval']<=ABS_THR, 'lastval']\n",
    "    \n",
    "    # case3. if the state is in the black list, then we don't use the pred above, instead, use the TS density\n",
    "    #        how to get this blacklist?\n",
    "    df.loc[df['state'].isin(blacklist), 'pred'] = df.loc[df['state'].isin(blacklist), 'lastval']\n",
    "    \n",
    "    # case4. if the cfips is in the black list, then we don't use the pred above, instead, use the TS density\n",
    "    df.loc[df['cfips'].isin(blacklistcfips), 'pred'] = df.loc[df['cfips'].isin(blacklistcfips), 'lastval']\n",
    "    \n",
    "    # FINALLY, assign the pred to the 'ypred' column of the 'raw' dataframe\n",
    "    raw.loc[raw.dcount==(TS+1), 'ypred'] = df['pred'].values\n",
    "    #          lastval is the actual density in TS, basically, you shift lag=1\n",
    "    raw.loc[raw.dcount==(TS+1), 'ypred_last'] = df['lastval'].values\n",
    "    \n",
    "    print(f'TS: {TS}')\n",
    "    print('Last Value SMAPE:', smape(df['microbusiness_density'], df['lastval']) )   # smape if you simply use last density to predict TS+1\n",
    "    print('XGB SMAPE:', smape(df['microbusiness_density'], df['pred']))              # smape if you use the preds\n",
    "    print()\n",
    "\n",
    "\n",
    "ind = (raw.dcount >= 30)&(raw.dcount <= 38)\n",
    "print( 'XGB SMAPE:', smape( raw.loc[ind, 'microbusiness_density'],  raw.loc[ind, 'ypred'] ) )\n",
    "print( 'Last Value SMAPE:', smape( raw.loc[ind, 'microbusiness_density'],  raw.loc[ind, 'ypred_last'] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-12T11:35:50.314755Z",
     "iopub.status.busy": "2023-01-12T11:35:50.314329Z",
     "iopub.status.idle": "2023-01-12T11:35:50.363503Z",
     "shell.execute_reply": "2023-01-12T11:35:50.362699Z",
     "shell.execute_reply.started": "2023-01-12T11:35:50.31471Z"
    }
   },
   "outputs": [],
   "source": [
    "raw['error'] = vsmape(raw['microbusiness_density'], raw['ypred'])\n",
    "raw['error_last'] = vsmape(raw['microbusiness_density'], raw['ypred_last'])\n",
    "raw.loc[(raw.dcount==30), ['cfips', 'microbusiness_density', 'ypred', 'ypred_last','error', 'error_last'] ].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Some post-hoc analysis after training and validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 which state has the most significant diff between the error (by pred) and the error_last (by last value pred)\n",
    "\n",
    "for example, it is better to use the actual xgb prediction for the district of columbia, instead of the last prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-12T11:35:50.365452Z",
     "iopub.status.busy": "2023-01-12T11:35:50.364893Z",
     "iopub.status.idle": "2023-01-12T11:35:50.40195Z",
     "shell.execute_reply": "2023-01-12T11:35:50.400629Z",
     "shell.execute_reply.started": "2023-01-12T11:35:50.365419Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dt = raw.loc[(raw.dcount>=30)&(raw.dcount<=38) ].groupby('state')['error', 'error_last'].mean()\n",
    "dt['hit'] = dt['error'] - dt['error_last']\n",
    "dt = dt.sort_values('hit', ascending=True)\n",
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-12T11:36:19.611588Z",
     "iopub.status.busy": "2023-01-12T11:36:19.610894Z",
     "iopub.status.idle": "2023-01-12T11:36:19.626116Z",
     "shell.execute_reply": "2023-01-12T11:36:19.62495Z",
     "shell.execute_reply.started": "2023-01-12T11:36:19.611526Z"
    }
   },
   "outputs": [],
   "source": [
    "dt.iloc[-10:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THIS IS WHERE THE BLACK LIST COMES FROM!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 which month has the biggest error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-12T11:37:16.484203Z",
     "iopub.status.busy": "2023-01-12T11:37:16.483765Z",
     "iopub.status.idle": "2023-01-12T11:37:16.51439Z",
     "shell.execute_reply": "2023-01-12T11:37:16.513333Z",
     "shell.execute_reply.started": "2023-01-12T11:37:16.484169Z"
    }
   },
   "outputs": [],
   "source": [
    "dt = raw.loc[(raw.dcount>=30)&(raw.dcount<=38) ].groupby('dcount')['error', 'error_last'].mean()\n",
    "dt['hit'] = dt['error'] - dt['error_last']\n",
    "dt = dt.sort_values('hit', ascending=False)\n",
    "dt.loc[dt['hit']>0]\n",
    "dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.3 stat err for each cfips and dcount, find out which dcount in which cfips has the biggest error diff between error_last and error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-12T11:38:41.111414Z",
     "iopub.status.busy": "2023-01-12T11:38:41.110995Z",
     "iopub.status.idle": "2023-01-12T11:38:41.156446Z",
     "shell.execute_reply": "2023-01-12T11:38:41.155252Z",
     "shell.execute_reply.started": "2023-01-12T11:38:41.111381Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dt = raw.loc[(raw.dcount>=30)&(raw.dcount<=38) ].groupby(['cfips','dcount'])['error', 'error_last'].mean()\n",
    "dt['hit'] = dt['error'] - dt['error_last']\n",
    "dt = dt.sort_values('hit', ascending=False).reset_index()\n",
    "dt.loc[dt['hit']>0]\n",
    "dt.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TOP 300 cfips with big diff, maybe duplicate inside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-12T11:38:44.32351Z",
     "iopub.status.busy": "2023-01-12T11:38:44.322833Z",
     "iopub.status.idle": "2023-01-12T11:38:44.333827Z",
     "shell.execute_reply": "2023-01-12T11:38:44.332458Z",
     "shell.execute_reply.started": "2023-01-12T11:38:44.323475Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dt.loc[dt['hit']>0].cfips.values[:300]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 TOP county that shouldn't use pred. instead, we should use last_value!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-12T11:39:20.016217Z",
     "iopub.status.busy": "2023-01-12T11:39:20.01499Z",
     "iopub.status.idle": "2023-01-12T11:39:20.046457Z",
     "shell.execute_reply": "2023-01-12T11:39:20.045206Z",
     "shell.execute_reply.started": "2023-01-12T11:39:20.016173Z"
    }
   },
   "outputs": [],
   "source": [
    "dt = raw.loc[(raw.dcount>=30)&(raw.dcount<=38) ].groupby('cfips')['error', 'error_last'].mean()\n",
    "dt['hit'] = dt['error'] - dt['error_last']\n",
    "dt = dt.sort_values('hit', ascending=False)\n",
    "dt = dt.loc[dt['hit']>0.00]\n",
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-12T11:39:20.36157Z",
     "iopub.status.busy": "2023-01-12T11:39:20.36051Z",
     "iopub.status.idle": "2023-01-12T11:39:20.371518Z",
     "shell.execute_reply": "2023-01-12T11:39:20.370365Z",
     "shell.execute_reply.started": "2023-01-12T11:39:20.361518Z"
    }
   },
   "outputs": [],
   "source": [
    "dt.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-12T11:40:01.778189Z",
     "iopub.status.busy": "2023-01-12T11:40:01.777753Z",
     "iopub.status.idle": "2023-01-12T11:40:01.817531Z",
     "shell.execute_reply": "2023-01-12T11:40:01.816109Z",
     "shell.execute_reply.started": "2023-01-12T11:40:01.778154Z"
    }
   },
   "outputs": [],
   "source": [
    "dt = raw.loc[(raw.dcount>=30)&(raw.dcount<=38) ].groupby(['cfips','dcount'])['error', 'error_last'].last()\n",
    "dt['miss'] = dt['error'] > dt['error_last']\n",
    "dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**for each county, the % that our XGB pred does worse than last preds**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-12T11:41:11.422688Z",
     "iopub.status.busy": "2023-01-12T11:41:11.422233Z",
     "iopub.status.idle": "2023-01-12T11:41:11.435323Z",
     "shell.execute_reply": "2023-01-12T11:41:11.434194Z",
     "shell.execute_reply.started": "2023-01-12T11:41:11.42265Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dt = dt.groupby('cfips')['miss'].mean()\n",
    "dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**if 50% XGB preds is worse than the last pred, show me these county**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-12T11:41:33.512503Z",
     "iopub.status.busy": "2023-01-12T11:41:33.512121Z",
     "iopub.status.idle": "2023-01-12T11:41:33.521149Z",
     "shell.execute_reply": "2023-01-12T11:41:33.519725Z",
     "shell.execute_reply.started": "2023-01-12T11:41:33.512469Z"
    }
   },
   "outputs": [],
   "source": [
    "dt = dt.loc[dt>=0.50]\n",
    "dt.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-12T11:41:48.770435Z",
     "iopub.status.busy": "2023-01-12T11:41:48.769464Z",
     "iopub.status.idle": "2023-01-12T11:41:48.776905Z",
     "shell.execute_reply": "2023-01-12T11:41:48.775613Z",
     "shell.execute_reply.started": "2023-01-12T11:41:48.770395Z"
    }
   },
   "outputs": [],
   "source": [
    "','.join([str(i) for i in dt.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-12T11:42:17.401111Z",
     "iopub.status.busy": "2023-01-12T11:42:17.400686Z",
     "iopub.status.idle": "2023-01-12T11:42:19.690269Z",
     "shell.execute_reply": "2023-01-12T11:42:19.688939Z",
     "shell.execute_reply.started": "2023-01-12T11:42:17.401074Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# show me the preds, WHY WHERE IS A LAG?????\n",
    "for d in dt.index[:10]:\n",
    "    raw.loc[raw.cfips==d].plot(x='dcount', y=['microbusiness_density', 'ypred'], title=str(d))\n",
    "    #raw.loc[raw.cfips==d].plot(x='dcount', y=['microbusiness_density', 'ypred_last'], title=str(d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-12T11:43:05.702657Z",
     "iopub.status.busy": "2023-01-12T11:43:05.702219Z",
     "iopub.status.idle": "2023-01-12T11:43:05.72632Z",
     "shell.execute_reply": "2023-01-12T11:43:05.724937Z",
     "shell.execute_reply.started": "2023-01-12T11:43:05.70262Z"
    }
   },
   "outputs": [],
   "source": [
    "df = raw.loc[(raw.dcount>=30)&(raw.dcount<=38) ].copy().reset_index(drop=True)\n",
    "print( smape(df['microbusiness_density'], df['ypred']) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-12T11:44:12.378683Z",
     "iopub.status.busy": "2023-01-12T11:44:12.378271Z",
     "iopub.status.idle": "2023-01-12T11:44:12.408828Z",
     "shell.execute_reply": "2023-01-12T11:44:12.407687Z",
     "shell.execute_reply.started": "2023-01-12T11:44:12.37865Z"
    }
   },
   "outputs": [],
   "source": [
    "dt = df.groupby(['cfips','dcount'])['error', 'error_last'].sum()\n",
    "dt['hit'] = 1*(dt['error'] < dt['error_last'])\n",
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-12T11:44:23.190883Z",
     "iopub.status.busy": "2023-01-12T11:44:23.190473Z",
     "iopub.status.idle": "2023-01-12T11:44:23.204103Z",
     "shell.execute_reply": "2023-01-12T11:44:23.202828Z",
     "shell.execute_reply.started": "2023-01-12T11:44:23.190838Z"
    }
   },
   "outputs": [],
   "source": [
    "dt = dt.groupby('cfips')['hit'].mean().sort_values(ascending=True)\n",
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-12T11:44:52.79715Z",
     "iopub.status.busy": "2023-01-12T11:44:52.796693Z",
     "iopub.status.idle": "2023-01-12T11:44:52.809851Z",
     "shell.execute_reply": "2023-01-12T11:44:52.808622Z",
     "shell.execute_reply.started": "2023-01-12T11:44:52.797111Z"
    }
   },
   "outputs": [],
   "source": [
    "# top 800 county that should use last_value prediction, NOT XGB predictions\n",
    "toplist = list(dt.index[:800])\n",
    "#print(toplist)\n",
    "\n",
    "# \n",
    "df.loc[df.cfips.isin(toplist), 'ypred'] = df.loc[df.cfips.isin(toplist), 'ypred_last']\n",
    "print( smape(df['microbusiness_density'], df['ypred']) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. LET'S GET THE PREDICTIONS FOR TS=38+1, WHICH IS 2022-11-01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-12T11:57:34.795914Z",
     "iopub.status.busy": "2023-01-12T11:57:34.795508Z",
     "iopub.status.idle": "2023-01-12T11:57:34.806232Z",
     "shell.execute_reply": "2023-01-12T11:57:34.80497Z",
     "shell.execute_reply.started": "2023-01-12T11:57:34.795882Z"
    }
   },
   "outputs": [],
   "source": [
    "np.mean( BEST_ROUNDS ), np.median( BEST_ROUNDS ), BEST_ROUNDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-12T11:57:35.565299Z",
     "iopub.status.busy": "2023-01-12T11:57:35.564924Z",
     "iopub.status.idle": "2023-01-12T11:57:35.573826Z",
     "shell.execute_reply": "2023-01-12T11:57:35.572649Z",
     "shell.execute_reply.started": "2023-01-12T11:57:35.565268Z"
    }
   },
   "outputs": [],
   "source": [
    "best_rounds = int(np.median( BEST_ROUNDS )+1)\n",
    "best_rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-12T11:57:36.196787Z",
     "iopub.status.busy": "2023-01-12T11:57:36.196126Z",
     "iopub.status.idle": "2023-01-12T11:57:59.699234Z",
     "shell.execute_reply": "2023-01-12T11:57:59.698321Z",
     "shell.execute_reply.started": "2023-01-12T11:57:36.19675Z"
    }
   },
   "outputs": [],
   "source": [
    "TS = 38\n",
    "print(TS)\n",
    "\n",
    "model0 = xgb.XGBRegressor(\n",
    "    objective='reg:pseudohubererror',\n",
    "    #objective='reg:squarederror',\n",
    "    tree_method=\"hist\",\n",
    "    n_estimators=best_rounds,  # now we have best round, so no early stopping\n",
    "    learning_rate=0.0075,\n",
    "    max_leaves = 31,           # the model used above has 17\n",
    "    subsample=0.60,            # the model used above has 0.50 \n",
    "    colsample_bytree=0.50,     \n",
    "    max_bin=4096,\n",
    "    n_jobs=2,\n",
    "    eval_metric='mae',           \n",
    ")\n",
    "\n",
    "model1 = xgb.XGBRegressor(\n",
    "    objective='reg:pseudohubererror',\n",
    "    #objective='reg:squarederror',\n",
    "    tree_method=\"hist\",\n",
    "    n_estimators=best_rounds,\n",
    "    learning_rate=0.0075,\n",
    "    max_leaves = 31,\n",
    "    subsample=0.60,\n",
    "    colsample_bytree=0.50,\n",
    "    max_bin=4096,\n",
    "    n_jobs=2,\n",
    "    eval_metric='mae',\n",
    ")\n",
    "\n",
    "train_indices = (raw.istest==0) & (raw.dcount  < TS) & (raw.dcount >= 1) & (raw.lastactive>ACT_THR)  & (raw.lasttarget>ABS_THR) \n",
    "valid_indices = (raw.dcount == TS)\n",
    "\n",
    "# I don't understand why we need two identical models. and then do a half / half ensemble\n",
    "model0.fit(\n",
    "    raw.loc[train_indices, features],\n",
    "    raw.loc[train_indices, 'target'].clip(-0.0044, 0.0046),\n",
    ")\n",
    "\n",
    "model1.fit(\n",
    "    raw.loc[train_indices, features],\n",
    "    raw.loc[train_indices, 'target'].clip(-0.0044, 0.0046),\n",
    ")\n",
    "\n",
    "ypred = (model0.predict(raw.loc[valid_indices, features]) + model1.predict(raw.loc[valid_indices, features])) / 2\n",
    "\n",
    "raw.loc[valid_indices, 'k'] = ypred + 1.\n",
    "raw.loc[valid_indices,'k'] = raw.loc[valid_indices,'k'] * raw.loc[valid_indices,'microbusiness_density'] # this is the pred for TS+1 = 39, although it is at TS\n",
    "\n",
    "# two mappings\n",
    "# 1. each cfips' microbusiness density in TS\n",
    "lastval = raw.loc[raw.dcount==TS, ['cfips', 'microbusiness_density']].set_index('cfips').to_dict()['microbusiness_density']\n",
    "# 2. each cfips' TS+1 prediction\n",
    "dt = raw.loc[raw.dcount==TS, ['cfips', 'k']].set_index('cfips').to_dict()['k']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-12T11:59:15.771423Z",
     "iopub.status.busy": "2023-01-12T11:59:15.771031Z",
     "iopub.status.idle": "2023-01-12T11:59:15.795565Z",
     "shell.execute_reply": "2023-01-12T11:59:15.794285Z",
     "shell.execute_reply.started": "2023-01-12T11:59:15.771392Z"
    }
   },
   "outputs": [],
   "source": [
    "df = raw.loc[raw.dcount==(TS+1), ['cfips', 'microbusiness_density', 'state', 'lastactive', 'mbd_lag_1']].reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-12T12:01:43.857894Z",
     "iopub.status.busy": "2023-01-12T12:01:43.857474Z",
     "iopub.status.idle": "2023-01-12T12:01:43.869287Z",
     "shell.execute_reply": "2023-01-12T12:01:43.868272Z",
     "shell.execute_reply.started": "2023-01-12T12:01:43.857839Z"
    }
   },
   "outputs": [],
   "source": [
    "df['pred'] = df['cfips'].map(dt)           # assign predictions to TS+1\n",
    "df['lastval'] = df['cfips'].map(lastval)   # assign TS density values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-12T12:01:44.767981Z",
     "iopub.status.busy": "2023-01-12T12:01:44.767572Z",
     "iopub.status.idle": "2023-01-12T12:01:44.788582Z",
     "shell.execute_reply": "2023-01-12T12:01:44.787276Z",
     "shell.execute_reply.started": "2023-01-12T12:01:44.767949Z"
    }
   },
   "outputs": [],
   "source": [
    "df.loc[df['lastactive']<=ACT_THR, 'pred'] = df.loc[df['lastactive']<=ACT_THR, 'lastval']\n",
    "df.loc[df['lastval']<=ABS_THR, 'pred'] = df.loc[df['lastval']<=ABS_THR, 'lastval']\n",
    "df.loc[df['state'].isin(blacklist), 'pred'] = df.loc[df['state'].isin(blacklist), 'lastval']\n",
    "df.loc[df['cfips'].isin(blacklistcfips), 'pred'] = df.loc[df['cfips'].isin(blacklistcfips), 'lastval']\n",
    "raw.loc[raw.dcount==(TS+1), 'ypred'] = df['pred'].values\n",
    "raw.loc[raw.dcount==(TS+1), 'ypred_last'] = df['lastval'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-12T12:02:23.069563Z",
     "iopub.status.busy": "2023-01-12T12:02:23.069184Z",
     "iopub.status.idle": "2023-01-12T12:02:23.093998Z",
     "shell.execute_reply": "2023-01-12T12:02:23.092917Z",
     "shell.execute_reply.started": "2023-01-12T12:02:23.069533Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raw[['cfips','microbusiness_density','dcount','ypred','ypred_last','k']].head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-12T12:05:01.440057Z",
     "iopub.status.busy": "2023-01-12T12:05:01.439676Z",
     "iopub.status.idle": "2023-01-12T12:05:01.534824Z",
     "shell.execute_reply": "2023-01-12T12:05:01.53377Z",
     "shell.execute_reply.started": "2023-01-12T12:05:01.440025Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raw.loc[raw['cfips']==28055, 'microbusiness_density'] = 0\n",
    "raw.loc[raw['cfips']==48269, 'microbusiness_density'] = 1.762115\n",
    "\n",
    "dt = raw.loc[raw.dcount==39, ['cfips', 'ypred']].set_index('cfips').to_dict()['ypred']\n",
    "test = raw.loc[raw.istest==1, ['row_id', 'cfips','microbusiness_density']].copy()\n",
    "test['microbusiness_density'] = test['cfips'].map(dt)\n",
    "\n",
    "test[['row_id','microbusiness_density']].to_csv('submission.csv', index=False)\n",
    "test.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
